# Контрольная работа по алгоритмическим структурам сортировки и поиска на языках: C++, Python, Java. (Хусяинова Камиля, УИБО-10-24)
# *Алгоритмы сортировки* 
## 1. Анализ алгоритма сортировки выбором
### Определение:
Сортировка выбором (Selection Sort) — на каждом шаге алгоритма находят минимальный элемент среди последних и меняют его местами с текущим элементом в массиве.
### __Как работает алгоритм:__
Программа запускается из ```main```, где создается массив и вызывается ```selectionSort()```. В методе сортировки внешний цикл ```for``` проходит по всем элементам. Для каждой позиции ```i``` внутренний цикл ```for``` ищет минимальный элемент в оставшейся части. Когда находится меньший элемент ```(if (arr[j] < arr[minIndex]))```, запоминается его позиция ```minIndex = j```. После завершения поиска элементы меняются местами через временную переменную ```temp```. Процесс повторяется для каждой позиции, постепенно формируя отсортированный массив. В конце ```main``` выводит результат через ```System.out.print()```.

### __Оценка временной сложности:__
Время - О(n²), где n — длина массива;	


Память - O(1).
### __Почему эта временная сложность?__
Временная сложность O(n²) вытекает потому, что выполняется n(n-1)/2 сравнений - для каждого элемента нужно проверить все оставшиеся в неотсортированной части массива.

## 2. Анализ алгоритма cортировки обменом (пузырьком)
### Определение:
Сортировка обменом (пузырьком) (Bubble Sort) — алгоритм проходит по списку несколько раз, сравнивая соседние элементы и меняя их местами, если они находятся в неправильном порядке. Процесс повторяется до тех пор, пока список полностью не отсортируется.
### __Как работает алгоритм:__
Функция ```bubble_sort()``` получает массив и определяет его длину ```n```. Внешний цикл ```for i in range(n)``` контролирует количество проходов. Внутренний цикл ```for j in range(0, n-i-1)``` сравнивает соседние элементы ```arr[j]``` и ```arr[j+1]```. Если они стоят в неправильном порядке, происходит обмен ```arr[j], arr[j+1] = arr[j+1], arr[j]```. Флаг swapped отслеживает, были ли обмены во время прохода. Если нет - массив уже отсортирован и цикл прерывается ```break```. Процесс повторяется до полной сортировки массива.

### __Оценка временной сложности:__
Время - О(n²), где n — длина массива;


Память - O(1).
### __Почему эта временная сложность?__
Временная сложность O(n²) вытекает потому, что для каждого из n элементов выполняется поиск минимального элемента в неотсортированной части, что требует в среднем n/2 сравнений на элемент, что приводит к n (n-1)/2 общим сравнениям.

## 3. Анализ алгоритма сортировка вставками 
### Определение:
(Insertion Sort) — алгоритм строит отсортированную часть списка, постепенно вставляя каждый элемент на своё место. Он начинает с первого элемента и перемещается вправо, сравнивая каждый элемент с предыдущими элементами и вставляя его на правильное место.
### __Как работает алгоритм:__
Функция ```insertionSort()``` получает вектор ```arr```. Начинается цикл ```for (int i = 1; i < n; i++)```, который обрабатывает каждый элемент начиная со второго. Для текущего элемента ```arr[i]``` сохраняется в переменную ```key```. Переменная ```j = i - 1``` указывает на предыдущий элемент. Цикл ```while (j >= 0 && arr[j] > key)``` сдвигает все элементы больше ```key``` на одну позицию вправо с помощью ```arr[j + 1] = arr[j]``` и уменьшает ```j--```. Когда найдена правильная позиция, ```key``` вставляется в массив командой ```arr[j + 1] = key```. Этот процесс повторяется для всех элементов, постепенно формируя отсортированную часть в начале вектора.

### __Оценка временной сложности:__
Время - О(n²), где n — длина массива;


Память - O(1).
### __Почему эта временная сложность?__
Временная сложность O(n²) вытекает потому, что в худшем случае каждый новый элемент требует сравнения и сдвига всех предыдущих элементов, что приводит к n(n-1)/2 операциям сравнения и обмена.

## 4. Анализ алгоритма сортировкаи слиянием 
### Определение:
Сортировка слиянием (Merge Sort) — алгоритм состоит в разделении массива пополам, сортировке половин и их слиянии.
### __Как работает алгоритм:__
Метод ```mergeSort``` проверяет условие ```if (left < right)``` - если часть массива больше одного элемента, вычисляется середина ```mid```. Затем рекурсивно вызывается ```mergeSort``` для левой и правой половин, после чего вызывается метод ```merge``` для их слияния.
В методе ```merge``` создаются два временных массива ```leftArray``` и ```rightArray```, куда копируются элементы из соответствующих половин. Затем три указателя ```i, j, k``` используются для слияния: сравниваются элементы из временных массивов и меньший помещается в исходный массив ```arr[k]```. Когда один из временных массивов заканчивается, оставшиеся элементы из другого копируются в конец.
Процесс повторяется рекурсивно, разбивая массив на мелкие части и затем сливая их в отсортированном порядке.

### __Оценка временной сложности:__
Время - O(n log n), где n — длина массива;


Память - O(1).
### __Почему эта временная сложность?__
Временная сложность O(n log n) вытекает потому, что массив делится пополам log n раз, и на каждом уровне рекурсии выполняется операция слияния всех n элементов, что в сумме дает n операций на log n уровней.

## 5. Анализ алгоритма сортировки Шелла 
### Определение:
Сортировка Шелла (Shell Sort) — является модификацией сортировки вставками, сортирует между собой элементы, стоящие на местах, кратных определённому шагу. 
### __Как работает алгоритм:__
Функция ```shell_sort``` начинает с вычисления большого шага ```gap = n // 2```. Внешний цикл ```while gap > 0``` выполняется, пока шаг не станет нулевым.
Для каждого шага внутренний цикл ```for i in range(gap, n)``` обрабатывает элементы, находящиеся на расстоянии ```gap```. Текущий элемент ```arr[i]``` сохраняется в ```temp```, затем вложенный цикл ```while j >= gap``` and ```arr[j - gap] > temp``` сдвигает элементы, превышающие ```temp```, на позиции с шагом ```gap```. Когда найдена правильная позиция, ```temp``` записывается в ```arr[j]```. После обработки всех элементов шаг уменьшается вдвое ```gap //= 2```, и процесс повторяется до полной сортировки.

### __Оценка временной сложности:__
Время - О(n²), где n — длина массива;


Память - O(1).
### __Почему эта временная сложность?__
Временная сложность O(n²) вытекает потому, что для последовательности расстояний n/2, n/4, ..., 1 в худшем случае может потребоваться квадратичное число операций, особенно когда массив отсортирован в обратном порядке.

## 6. Анализ алгоритма быстрой сортировки
### Определение:
Быстрая сортировка (Quick Sort) — один из самых известных и широко используемых алгоритмов сортировки. Алгоритм состоит в выборе опорного элемента, разделении массива на две части относительно опорного (одна — все элементы, меньшие опорного элемента, вторая — большие), и в сортировке полученных частей рекурсивным вызовом себя от них.
### __Как работает алгоритм:__
Функция ```quickSort``` проверяет условие ```if (low < high)```, затем вызывает ```partition```, которая выбирает опорный элемент ```pivot = arr[high]```. Указатель ```i``` отслеживает позицию для элементов меньше опорного. В цикле ```for``` элементы, меньшие или равные ```pivot```, перемещаются влево с помощью ```swap(arr[i], arr[j])```. После цикла опорный элемент ставится на правильную позицию ```swap(arr[i + 1], arr[high])```, которая возвращается как ```pi```. Рекурсивно вызывается ```quickSort``` для левой и правой частей относительно опорного элемента. Процесс повторяется, пока все части не будут отсортированы.

### __Оценка временной сложности:__
Время - O(n log n), где n — длина массива;


Память - O(log n).
### __Почему эта временная сложность?__
Временная сложность O(n log n) вытекает потому, что в среднем случае массив делится на примерно равные части на каждом уровне рекурсии, создавая log n уровней, где на каждом уровне выполняется операция разделения, требующая O(n) сравнений и обменов.


## 7. Анализ алгоритма пирамидальной сортировки
### Определение:
Пирамидальная сортировка (Heap Sort) — алгоритм строит кучу из исходного списка, затем постепенно извлекает наибольший элемент из кучи и помещает его в конец списка.
### __Как работает алгоритм:__
Метод ```heapSort``` сначала строит ```max-heap``` из массива, проходя циклом ```for``` от середины к началу и вызывая ```heapify``` для каждого элемента. После построения кучи начинается извлечение элементов: корень (максимальный элемент) перемещается в конец массива через обмен ```arr[0]``` и ```arr[i]```, затем вызывается ```heapify``` для восстановления свойств кучи на уменьшенном массиве.
Метод ```heapify``` проверяет, является ли узел ```i``` наибольшим среди него и его потомков ```left``` и ```right```. Если нет - происходит обмен с наибольшим потомком и рекурсивный вызов ```heapify``` для измененного поддерева. Процесс повторяется до полной сортировки массива.

### __Оценка временной сложности:__
Время - O(n log n), где n — длина массива;


Память - O(1).
### __Почему эта временная сложность?__
Временная сложность O(n log n) вытекает потому, что построение кучи занимает O(n) времени, а каждое из n извлечений максимального элемента требует O(log n) времени для перестройки кучи, что в сумме дает O(n) + O(n log n) = O(n log n) операций.

# *Алгоритмы поиска*
## 1. Анализ алгоритма линейного поиска
### Определение:
Последовательный (линейный) поиск (Linear Search) — простейший вид поиска заданного элемента на некотором множестве. Осуществляется путём последовательного сравнения очередного рассматриваемого значения с искомым до тех пор, пока эти значения не совпадут. Этот метод является наименее эффективным, так как его временная сложность составляет O(n), где n — количество элементов в списке. Однако он прост в реализации и может быть полезен для небольших списков или в тех случаях, когда данные не отсортированы.
### __Как работает алгоритм:__
Функция ```linear_search``` последовательно перебирает элементы массива в цикле ```for i in range(len(arr))```. На каждой итерации проверяется условие ```if arr[i] == target```. Если элемент найден, функция немедленно возвращает его индекс ```i```. Если цикл завершается без нахождения элемента, возвращается -1. Это простой алгоритм, который проверяет каждый элемент до тех пор, пока не найдет искомый или не достигнет конца массива.

### __Оценка временной сложности:__
Время - O(n), где n — длина массива;


Память - O(1).
### __Почему эта временная сложность?__
Временная сложность O(n) вытекает потому, что в худшем случае алгоритму требуется проверить все n элементов массива для нахождения искомого значения, при этом количество операций растет линейно с увеличением размера массива.

## 2. Анализ алгоритма бинарного поиска
### Определение:
Бинарный (двоичный, дихотомический) поиск (Binary Search) — это поиск заданного элемента на упорядоченном множестве, осуществляемый путём неоднократного деления этого множества на две части таким образом, что искомый элемент попадает в одну из этих частей. Поиск заканчивается при совпадении искомого элемента с элементом, который является границей между частями множества или при отсутствии искомого элемента. Преимуществом бинарного поиска является более низкая трудоёмкость по сравнению с последовательным поиском. Недостаток заключается в том, что он применим только на отсортированных множествах.
### __Как работает алгоритм:__
Функция ```binarySearch``` работает с отсортированным массивом. Она использует два указателя ```left``` и ```right```, обозначающих текущий диапазон поиска. В цикле ```while``` вычисляется средний индекс ```mid```. Если элемент в середине равен целевому, возвращается его позиция. Если целевой элемент больше среднего, поиск продолжается в правой половине ```(left = mid + 1)```. Если меньше - в левой ```(right = mid - 1)```. Если элемент не найден, возвращается -1.

### __Оценка временной сложности:__
Время - O(log n), где n — длина массива;


Память - O(1).
### __Почему эта временная сложность?__
Временная сложность O(log n) вытекает потому, что на каждом шаге алгоритма область поиска уменьшается вдвое, что означает, что даже для массива из миллиона элементов потребуется не более 20 сравнений для нахождения искомого элемента или определения его отсутствия.


## 3. Анализ алгоритма интерполяционного поиска
### Определение:
Интерполирующий поиск (Interpolation Search) — это алгоритм поиска для отсортированных наборов данных, таких как массивы или списки. Он предсказывает позицию нужного элемента на основе разницы значений. Эффективен, если элементы распределены достаточно равномерно.
### __Как работает алгоритм:__
Функция ```interpolationSearch``` использует интерполяционную формулу для предсказания позиции искомого элемента в отсортированном массиве. В цикле ```while``` вычисляется ```pos``` на основе значений ```target, arr[low] и arr[high]```. Если элемент в позиции pos равен целевому, возвращается индекс. Если меньше - поиск продолжается справа ```(low = pos + 1)```, если больше - слева ```(high = pos - 1)```. Цикл выполняется пока ```target``` находится в границах текущего диапазона поиска. Если элемент не найден, возвращается -1.

### __Оценка временной сложности:__
Время - O(log log n), где n — длина массива;


Память - O(1).
### __Почему эта временная сложность?__
Временная сложность O(log log n) вытекает потому, что при равномерном распределении данных алгоритм экспоненциально уменьшает область поиска на каждом шаге, находя элемент за двойной логарифм от количества элементов.


## 4. Анализ алгоритма поиска по Фибоначчи
### Определение:
Поиск по Фибоначчи (Fibonacci Search) — это эффективный алгоритм поиска, используемый для нахождения целевого значения в отсортированной коллекции, такой как массив или список. По принципу он аналогичен бинарному поиску, но использует числа Фибоначчи для определения позиций для сравнения.
### __Как работает алгоритм:__
Функция ```fibonacci_search``` использует числа Фибоначчи для поиска в отсортированном массиве. Сначала генерируется последовательность Фибоначчи до числа ```fib_m```, превышающего длину массива.
В основном цикле ```while fib_m > 1``` вычисляется позиция ```i``` для сравнения. Если ```arr[i]``` меньше целевого, поиск продолжается справа с обновлением переменных Фибоначчи и смещения ```offset```. Если ```arr[i]``` больше целевого, поиск продолжается слева с уменьшением переменных Фибоначчи. При нахождении элемента возвращается его индекс. В завершении проверяется последний возможный элемент. Если элемент не найден, возвращается -1.

### __Оценка временной сложности:__
Время - O(log n), где n — длина массива;


Память - O(1).
### __Почему эта временная сложность?__
Временная сложность O(log n) вытекает потому, что алгоритм делит массив с помощью чисел Фибоначчи, которые растут экспоненциально, что гарантирует логарифмическое количество сравнений относительно размера массива, аналогично бинарному поиску.
